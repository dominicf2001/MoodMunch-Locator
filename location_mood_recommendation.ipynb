{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> Food Recommendation Base On Emotion for College Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for food dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 125 entries, 0 to 124\n",
      "Data columns (total 61 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   GPA                           123 non-null    object \n",
      " 1   Gender                        125 non-null    int64  \n",
      " 2   breakfast                     125 non-null    int64  \n",
      " 3   calories_chicken              125 non-null    int64  \n",
      " 4   calories_day                  106 non-null    float64\n",
      " 5   calories_scone                124 non-null    float64\n",
      " 6   coffee                        125 non-null    int64  \n",
      " 7   comfort_food                  124 non-null    object \n",
      " 8   comfort_food_reasons          123 non-null    object \n",
      " 9   comfort_food_reasons_coded    106 non-null    float64\n",
      " 10  cook                          122 non-null    float64\n",
      " 11  comfort_food_reasons_coded.1  125 non-null    int64  \n",
      " 12  cuisine                       108 non-null    float64\n",
      " 13  diet_current                  124 non-null    object \n",
      " 14  diet_current_coded            125 non-null    int64  \n",
      " 15  drink                         123 non-null    float64\n",
      " 16  eating_changes                122 non-null    object \n",
      " 17  eating_changes_coded          125 non-null    int64  \n",
      " 18  eating_changes_coded1         125 non-null    int64  \n",
      " 19  eating_out                    125 non-null    int64  \n",
      " 20  employment                    116 non-null    float64\n",
      " 21  ethnic_food                   125 non-null    int64  \n",
      " 22  exercise                      112 non-null    float64\n",
      " 23  father_education              124 non-null    float64\n",
      " 24  father_profession             122 non-null    object \n",
      " 25  fav_cuisine                   123 non-null    object \n",
      " 26  fav_cuisine_coded             125 non-null    int64  \n",
      " 27  fav_food                      123 non-null    float64\n",
      " 28  food_childhood                124 non-null    object \n",
      " 29  fries                         125 non-null    int64  \n",
      " 30  fruit_day                     125 non-null    int64  \n",
      " 31  grade_level                   125 non-null    int64  \n",
      " 32  greek_food                    125 non-null    int64  \n",
      " 33  healthy_feeling               125 non-null    int64  \n",
      " 34  healthy_meal                  124 non-null    object \n",
      " 35  ideal_diet                    124 non-null    object \n",
      " 36  ideal_diet_coded              125 non-null    int64  \n",
      " 37  income                        124 non-null    float64\n",
      " 38  indian_food                   125 non-null    int64  \n",
      " 39  italian_food                  125 non-null    int64  \n",
      " 40  life_rewarding                124 non-null    float64\n",
      " 41  marital_status                124 non-null    float64\n",
      " 42  meals_dinner_friend           122 non-null    object \n",
      " 43  mother_education              122 non-null    float64\n",
      " 44  mother_profession             123 non-null    object \n",
      " 45  nutritional_check             125 non-null    int64  \n",
      " 46  on_off_campus                 124 non-null    float64\n",
      " 47  parents_cook                  125 non-null    int64  \n",
      " 48  pay_meal_out                  125 non-null    int64  \n",
      " 49  persian_food                  124 non-null    float64\n",
      " 50  self_perception_weight        124 non-null    float64\n",
      " 51  soup                          124 non-null    float64\n",
      " 52  sports                        123 non-null    float64\n",
      " 53  thai_food                     125 non-null    int64  \n",
      " 54  tortilla_calories             124 non-null    float64\n",
      " 55  turkey_calories               125 non-null    int64  \n",
      " 56  type_sports                   99 non-null     object \n",
      " 57  veggies_day                   125 non-null    int64  \n",
      " 58  vitamins                      125 non-null    int64  \n",
      " 59  waffle_calories               125 non-null    int64  \n",
      " 60  weight                        123 non-null    object \n",
      "dtypes: float64(20), int64(27), object(14)\n",
      "memory usage: 59.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPA                  2\n",
       "Gender               0\n",
       "breakfast            0\n",
       "calories_chicken     0\n",
       "calories_day        19\n",
       "                    ..\n",
       "type_sports         26\n",
       "veggies_day          0\n",
       "vitamins             0\n",
       "waffle_calories      0\n",
       "weight               2\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_recommend = pd.read_csv('dataset/food_coded.csv') \n",
    "food_recommend.info()\n",
    "food_recommend.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Food dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food Types</th>\n",
       "      <th>Emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>none</td>\n",
       "      <td>we dont have comfort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chocolate, chips, ice cream</td>\n",
       "      <td>Stress, bored, anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frozen yogurt, pizza, fast food</td>\n",
       "      <td>stress, sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pizza, Mac and cheese, ice cream</td>\n",
       "      <td>Boredom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ice cream, chocolate, chips</td>\n",
       "      <td>Stress, boredom, cravings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>wine. mac and cheese, pizza, ice cream</td>\n",
       "      <td>boredom and sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Pizza / Wings / Cheesecake</td>\n",
       "      <td>Loneliness / Homesick / Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>rice, potato, seaweed soup</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Mac n Cheese, Lasagna, Pizza</td>\n",
       "      <td>happiness, they are some of my favorite foods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Chocolates, pizza, and Ritz.</td>\n",
       "      <td>hormones, Premenstrual syndrome.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Food Types  \\\n",
       "0                                       none   \n",
       "1                chocolate, chips, ice cream   \n",
       "2            frozen yogurt, pizza, fast food   \n",
       "3           Pizza, Mac and cheese, ice cream   \n",
       "4               Ice cream, chocolate, chips    \n",
       "..                                       ...   \n",
       "120  wine. mac and cheese, pizza, ice cream    \n",
       "121               Pizza / Wings / Cheesecake   \n",
       "122               rice, potato, seaweed soup   \n",
       "123             Mac n Cheese, Lasagna, Pizza   \n",
       "124             Chocolates, pizza, and Ritz.   \n",
       "\n",
       "                                          Emotions  \n",
       "0                            we dont have comfort   \n",
       "1                             Stress, bored, anger  \n",
       "2                                  stress, sadness  \n",
       "3                                          Boredom  \n",
       "4                       Stress, boredom, cravings   \n",
       "..                                             ...  \n",
       "120                           boredom and sadness   \n",
       "121                Loneliness / Homesick / Sadness  \n",
       "122                                        sadness  \n",
       "123  happiness, they are some of my favorite foods  \n",
       "124               hormones, Premenstrual syndrome.  \n",
       "\n",
       "[125 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_recommend = pd.read_csv('dataset/food_coded.csv', sep=',', usecols=['comfort_food', 'comfort_food_reasons'])\n",
    "\n",
    "# only take two attributes comfort_food and comfort_food_reason and rename\n",
    "food_recommend.rename(columns={'comfort_food': 'Food Types', 'comfort_food_reasons': 'Emotions'}, inplace=True)\n",
    "food_recommend\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data clean: clean or fill NaN values in 'comfort_food_reasons' and 'comfort_food' columns\n",
    "\n",
    "#### There is some NaN in the dataset, it could being treat as int. So we need to clean that or fill with empty str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_recommend[\"Emotions\"] = food_recommend[\"Emotions\"].fillna(\"\")\n",
    "food_recommend[\"Food Types\"] = food_recommend[\"Food Types\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "## Data Processing with NLTK\n",
    "- Apply NLTK Stopwords to filter out all common words. These are common words used in any language (such as \"the\", \"is\", \"in\", \"and\") that are often filtered out before processing text because they don't have important meaning and are very frequent. \n",
    "    - In this project, we are not only stop common word, but we also extended with some punctuation marks with \"stop.update()\n",
    "    - When processing each emotions_item, we split text into individual words and removes these stopwords. This helps in focusing on words that are more likely to hold specific meaning related to mood\n",
    "- Apply NLTK Lemmatizer to reduce or filter the part in words base on it root. It's the process of reducing words to their base or dictionary form. It treats different forms of a word as the same item, which is useful in counting, searching, or categorizing.\n",
    "    - In this project, WordNetLemmatizer is used to lemmatize each word in the \"emotions\" and \"foods\". So all words could convert to its base form\n",
    "    - Example: sadness -> sad, boredome -> bore/bored\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Filter all common words\n",
    "stop = set(stopwords.words('english'))\n",
    "stop.update(['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}',''])\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "food_count = {}\n",
    "\n",
    "\"\"\"\n",
    "    Finds the top comfort foods associated with a given mood.\n",
    "\n",
    "    emotion (str): The emotion to search for.\n",
    "    food_recommend (DataFrame): DataFrame containing 'Food Types' and 'Emotions' columns.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of the top comfort foods for the given mood.\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "# Processing\n",
    "def preprocess_text(emotion, food_recommend):\n",
    "\n",
    "    # Looping through the food data\n",
    "    for i in range(len(food_recommend)):\n",
    "\n",
    "        # PROCESS \"comfort_food_reasons\"\n",
    "        emotions_item = food_recommend[\"Emotions\"][i]\n",
    "        # Convert all items in comfort_food_reasons to str included NaN value.\n",
    "        # Split it into individual words, removes punctuation (. ,) and converts to lowercase\n",
    "        # checks if each word is not a stop word. (and with NLTK, common words will be removed such as \"I\",\"and\")\n",
    "        if isinstance(emotions_item, str):\n",
    "            emotions = emotions_item.lower().split()\n",
    "            emotions = [lemmatizer.lemmatize(word.strip('.,')) for word in emotions if word not in stop]\n",
    "\n",
    "        # PROCESS \"comfort_food\"\n",
    "        # If the mood is found, the processed similarly: split into item, punctuation removed, converted to lowercase, and lemmatized\n",
    "        if emotion in emotions:\n",
    "            foods = food_recommend[\"Food Types\"][i].lower().split(',')\n",
    "            foods = [lemmatizer.lemmatize(food.strip().strip('.,')) for food in foods if food not in stop]\n",
    "\n",
    "        # Add process food to food count and count food\n",
    "        # If the item is new to the dictionary, added with a count of 1; if it already exists, its count is incremented\n",
    "            for itemfood in foods:\n",
    "                if itemfood not in food_count.keys():\n",
    "                     food_count[itemfood] = 1 \n",
    "                else:\n",
    "                     food_count[itemfood] += 1\n",
    "\n",
    "    # Now specified mood is already associated with food.\n",
    "    # Sorting and selecting the top foods (most to least appearing food)\n",
    "    top_foods = sorted(food_count, key=food_count.get, reverse=True)[:10]\n",
    "    return top_foods\n",
    "\n",
    "\n",
    "def food_result(emotion):\n",
    "    topn = []\n",
    "    topn = preprocess_text(emotion, food_recommend) #function create dictionary only for particular mood\n",
    "    print(f\"10 Popular Comfort Foods in {emotion} are:\")\n",
    "    # print(topn[0])\n",
    "    # print(topn[1])\n",
    "    # print(topn[2]) \n",
    "    # print(topn[3]) \n",
    "    # print(topn[4]) \n",
    "    # print(topn[5]) \n",
    "    for food in topn:\n",
    "        print(food)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Popular Comfort Foods in sad are:\n",
      "ice cream\n",
      "pizza\n",
      "chip\n",
      "cheeseburger\n",
      "french fries\n",
      "fry\n",
      "cereal\n",
      "cooky\n",
      "chicken wings\n",
      "pasta\n"
     ]
    }
   ],
   "source": [
    "#food_result('bored')         10\n",
    "# food_result('blue')          0\n",
    "#food_result('yellow')        0\n",
    "#food_result('satisfaction')  3\n",
    "#food_result('late')           3\n",
    "food_result('sad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation for restaurant dataset\n",
    "<a href=https://towardsdatascience.com/load-yelp-reviews-or-other-huge-json-files-with-ease-ad804c2f1537>Link For Load yelp review (huge json file) </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>New Orleans</td>\n",
       "      <td>LA</td>\n",
       "      <td>29.941468</td>\n",
       "      <td>-90.129953</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Kenner</td>\n",
       "      <td>LA</td>\n",
       "      <td>29.981183</td>\n",
       "      <td>-90.254012</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>New Orleans</td>\n",
       "      <td>LA</td>\n",
       "      <td>29.951359</td>\n",
       "      <td>-90.064672</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Harvey</td>\n",
       "      <td>LA</td>\n",
       "      <td>29.875482</td>\n",
       "      <td>-90.049380</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>New Orleans</td>\n",
       "      <td>LA</td>\n",
       "      <td>29.958431</td>\n",
       "      <td>-90.065173</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150242</th>\n",
       "      <td>New Orleans</td>\n",
       "      <td>LA</td>\n",
       "      <td>29.926070</td>\n",
       "      <td>-90.082950</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150251</th>\n",
       "      <td>New Orleans</td>\n",
       "      <td>LA</td>\n",
       "      <td>29.942775</td>\n",
       "      <td>-90.187162</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150283</th>\n",
       "      <td>Kenner</td>\n",
       "      <td>LA</td>\n",
       "      <td>30.033566</td>\n",
       "      <td>-90.238520</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150296</th>\n",
       "      <td>Metairie</td>\n",
       "      <td>LA</td>\n",
       "      <td>30.005648</td>\n",
       "      <td>-90.157396</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150300</th>\n",
       "      <td>New Orleans</td>\n",
       "      <td>LA</td>\n",
       "      <td>30.022340</td>\n",
       "      <td>-90.052255</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9924 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               city state   latitude  longitude  stars\n",
       "17      New Orleans    LA  29.941468 -90.129953    4.0\n",
       "18           Kenner    LA  29.981183 -90.254012    3.5\n",
       "34      New Orleans    LA  29.951359 -90.064672    3.0\n",
       "60           Harvey    LA  29.875482 -90.049380    2.5\n",
       "65      New Orleans    LA  29.958431 -90.065173    4.0\n",
       "...             ...   ...        ...        ...    ...\n",
       "150242  New Orleans    LA  29.926070 -90.082950    4.5\n",
       "150251  New Orleans    LA  29.942775 -90.187162    4.0\n",
       "150283       Kenner    LA  30.033566 -90.238520    4.5\n",
       "150296     Metairie    LA  30.005648 -90.157396    3.0\n",
       "150300  New Orleans    LA  30.022340 -90.052255    4.0\n",
       "\n",
       "[9924 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert yelp_business.json to csv\n",
    "restaurant_location = pd.read_json('dataset/yelp_academic_dataset_business.json', lines=True)\n",
    "restaurant_location.to_csv('dataset/restaurant_location.csv', index=False)\n",
    "\n",
    "restaurant_location = pd.read_csv('dataset/restaurant_location.csv', sep=',')\n",
    "# restaurant_location.info()\n",
    "df = restaurant_location[['city','state','latitude','longitude','stars']]\n",
    "df.query(\"`state`=='LA'\")\n",
    "#df.query(\"`state`=='OH'\")\n",
    "\n",
    "\n",
    "\n",
    "# a_pandas = []\n",
    "# r_dtypes = {}\n",
    "\n",
    "# with open('dataset/yelp_academic_dataset_business.json', 'r') as f:\n",
    "#     df = pd.read_json(f, orient=\"records\", lines=True, dtype=r_dtypes, chunksize=1000)\n",
    "\n",
    "        \n",
    "#     for chunk in df:\n",
    "#         reduced_chunk = chunk.drop(columns=['business_id', 'address','review_count', 'attributes','hours'])\\\n",
    "#                              .query(\"`state` == 'OH'\")\n",
    "                            \n",
    "#         a_pandas.append(reduced_chunk)\n",
    "    \n",
    "# a_pandas = pd.concat(a_pandas, ignore_index=True)\n",
    "# a_pandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3Z59UMun90xRiSU1XX8rhQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>We have been ordering here for the last few ye...</td>\n",
       "      <td>2020-12-04 22:20:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YB26JvvGS2LgkxEKOObSAw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I've been eating at this restaurant for over 5...</td>\n",
       "      <td>2021-01-08 01:49:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>raKflkp3CANr8N7qpQ3ZyQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I WISH I was still a Sierra resident. They're ...</td>\n",
       "      <td>2021-02-02 18:14:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S-VD26LE_LeJNx5nASk_pw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The service is always good, the employees are ...</td>\n",
       "      <td>2021-01-26 18:01:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yE1raqkLX7OZsjmX3qKIKg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>two words: whipped. feta. \\nexplosion of amazi...</td>\n",
       "      <td>2021-01-27 23:28:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456037</th>\n",
       "      <td>58MJvmfo5hyfBbvkr54sFA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Great gym.  Was in Indy for 4 days on business...</td>\n",
       "      <td>2022-01-18 15:24:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456038</th>\n",
       "      <td>e_E-jq9mwm7wk75k7Yi-Xw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>It is very rare for a restaurant to be this go...</td>\n",
       "      <td>2022-01-17 22:36:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456039</th>\n",
       "      <td>6WaI-IN8ql0xpEKlb4q8tg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>We redesigned my moms dress and mad it complet...</td>\n",
       "      <td>2022-01-17 20:59:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456040</th>\n",
       "      <td>2vLksaMmSEcGbjI5gywpZA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This spot offers a great, affordable east week...</td>\n",
       "      <td>2021-03-31 16:55:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456041</th>\n",
       "      <td>Rr9kKArrMhSLVE9a53q-aA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>For when I'm feeling like ignoring my calorie-...</td>\n",
       "      <td>2022-01-19 18:59:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>456042 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   business_id  stars  \\\n",
       "0       3Z59UMun90xRiSU1XX8rhQ    5.0   \n",
       "1       YB26JvvGS2LgkxEKOObSAw    5.0   \n",
       "2       raKflkp3CANr8N7qpQ3ZyQ    5.0   \n",
       "3       S-VD26LE_LeJNx5nASk_pw    5.0   \n",
       "4       yE1raqkLX7OZsjmX3qKIKg    5.0   \n",
       "...                        ...    ...   \n",
       "456037  58MJvmfo5hyfBbvkr54sFA    5.0   \n",
       "456038  e_E-jq9mwm7wk75k7Yi-Xw    5.0   \n",
       "456039  6WaI-IN8ql0xpEKlb4q8tg    5.0   \n",
       "456040  2vLksaMmSEcGbjI5gywpZA    5.0   \n",
       "456041  Rr9kKArrMhSLVE9a53q-aA    5.0   \n",
       "\n",
       "                                                     text                date  \n",
       "0       We have been ordering here for the last few ye... 2020-12-04 22:20:16  \n",
       "1       I've been eating at this restaurant for over 5... 2021-01-08 01:49:36  \n",
       "2       I WISH I was still a Sierra resident. They're ... 2021-02-02 18:14:15  \n",
       "3       The service is always good, the employees are ... 2021-01-26 18:01:45  \n",
       "4       two words: whipped. feta. \\nexplosion of amazi... 2021-01-27 23:28:03  \n",
       "...                                                   ...                 ...  \n",
       "456037  Great gym.  Was in Indy for 4 days on business... 2022-01-18 15:24:44  \n",
       "456038  It is very rare for a restaurant to be this go... 2022-01-17 22:36:01  \n",
       "456039  We redesigned my moms dress and mad it complet... 2022-01-17 20:59:01  \n",
       "456040  This spot offers a great, affordable east week... 2021-03-31 16:55:10  \n",
       "456041  For when I'm feeling like ignoring my calorie-... 2022-01-19 18:59:27  \n",
       "\n",
       "[456042 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## unable to load Yelp reviews (other huge JSON yelp_review.json). Over 5gb\n",
    "# restaurant_review = pd.read_json('dataset/yelp_academic_dataset_review.json', lines=True, chunksize=1000 )\n",
    "# restaurant_review.to_csv('dataset/restaurant_review.csv', index=False)\n",
    "# restaurant_review\n",
    "\n",
    "\n",
    "b_pandas = []\n",
    "r_dtypes = {\"stars\": np.float16}\n",
    "\n",
    "with open('dataset/yelp_academic_dataset_review.json', 'r') as f:\n",
    "    df = pd.read_json(f, orient=\"records\", lines=True, dtype=r_dtypes, chunksize=1000)\n",
    "\n",
    "    for chunk in df:\n",
    "        reduced_chunk = chunk.drop(columns=['review_id', 'user_id', 'useful', 'funny', 'cool'])\\\n",
    "                             .query(\"`date` >= '2020-12-01'\").query(\"`stars` >= 3.9\")\n",
    "        b_pandas.append(reduced_chunk)\n",
    "    \n",
    "b_pandas = pd.concat(b_pandas, ignore_index=True)\n",
    "b_pandas\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
